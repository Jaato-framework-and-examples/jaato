# .env.example - Copy to .env and fill in values

# =============================================================================
# Provider Selection
# =============================================================================
# Choose which model provider to use. Options:
#   google_genai  - Google AI Studio / Vertex AI (Gemini models)
#   github_models - GitHub Models API (GPT, Claude, Gemini, Llama via GitHub)
#
# Default: google_genai
JAATO_PROVIDER=google_genai

# =============================================================================
# Model Configuration
# =============================================================================
# Model name depends on provider:
#   google_genai:  gemini-2.5-flash, gemini-2.5-pro, gemini-2.0-flash, etc.
#   github_models: openai/gpt-4o, anthropic/claude-sonnet-4, meta/llama-3.1-70b-instruct, etc.
#
MODEL_NAME=gemini-2.5-flash

# =============================================================================
# Google GenAI Authentication (for JAATO_PROVIDER=google_genai)
# =============================================================================
# Choose ONE of the following authentication methods:

# --- Option A: Google AI Studio (personal/development) ---
# Simple API key authentication for quick development and personal use.
# Get your key at: https://aistudio.google.com/apikey
#
# GOOGLE_GENAI_API_KEY=your-api-key-from-ai-studio

# --- Option B: Vertex AI (organization/production) ---
# GCP-based authentication for enterprise use with billing and access controls.
#
# Project and location (required for Vertex AI)
# JAATO_GOOGLE_PROJECT=your-gcp-project-id
# JAATO_GOOGLE_LOCATION=us-central1
#
# Authentication options (choose one):
# 1. Application Default Credentials (recommended for local dev):
#    Run: gcloud auth application-default login
#
# 2. Service account key file (for CI/CD and production):
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account-key.json
#
# 3. Service account impersonation (for least-privilege and cross-project access):
# JAATO_GOOGLE_TARGET_SERVICE_ACCOUNT=target-sa@project.iam.gserviceaccount.com
# JAATO_GOOGLE_AUTH_METHOD=impersonation

# --- Google Auth Method Selection (optional) ---
# Explicitly set authentication method. If not set, auto-detected from
# available credentials (api_key > target_service_account > service_account_file > adc).
#
# Options: auto, api_key, service_account_file, adc, impersonation
# JAATO_GOOGLE_AUTH_METHOD=auto
#
# Force Vertex AI (true) or AI Studio (false) endpoint:
# JAATO_GOOGLE_USE_VERTEX=true

# =============================================================================
# GitHub Models Authentication (for JAATO_PROVIDER=github_models)
# =============================================================================
# Access GPT, Claude, Gemini, Llama, and more through GitHub's Models API.
# Free tier available for all GitHub accounts (with token limits).
#
# Create a fine-grained PAT at: https://github.com/settings/tokens?type=beta
# Required permission: Account permissions → Models → Read
#
# GITHUB_TOKEN=github_pat_your-token-here
#
# Optional: Organization for billing attribution
# JAATO_GITHUB_ORGANIZATION=your-org
#
# Optional: Enterprise name (for context/debugging)
# JAATO_GITHUB_ENTERPRISE=your-enterprise
#
# Optional: Override API endpoint (default: https://models.github.ai/inference)
# JAATO_GITHUB_ENDPOINT=https://models.github.ai/inference

# =============================================================================
# Legacy Variables (still supported for backwards compatibility)
# =============================================================================
# PROJECT_ID=your-gcp-project-id
# LOCATION=us-central1

# =============================================================================
# Optional: MCP Server Credentials
# =============================================================================
# Note: GITHUB_TOKEN is also used by the MCP GitHub server.

# Confluence credentials for MCP Atlassian server
# CONFLUENCE_URL=https://your-domain.atlassian.net
# CONFLUENCE_USERNAME=your-email@example.com
# CONFLUENCE_API_TOKEN=your-confluence-api-token

# =============================================================================
# Optional: Rate Limiting and Retry Settings
# =============================================================================
# Proactive rate limiting (prevents 429 errors)
# AI_REQUEST_INTERVAL=0.5       # Minimum seconds between API requests (0 = disabled)

# Reactive retry (handles 429 errors when they occur)
# AI_RETRY_ATTEMPTS=5           # Max retry attempts for transient errors
# AI_RETRY_BASE_DELAY=1.0       # Initial retry delay in seconds
# AI_RETRY_MAX_DELAY=30.0       # Maximum retry delay in seconds
# AI_RETRY_LOG_SILENT=false     # Set to 'true' to suppress retry logging

# =============================================================================
# Optional: Debug Settings
# =============================================================================
# AI_USE_CHAT_FUNCTIONS=1
# VERBOSE=1

# =============================================================================
# Optional: Plugin Configuration Paths
# =============================================================================
# Override default config file locations for plugins.
# Default locations are typically .jaato/<plugin>.json or <plugin>.json in cwd.
#
# FILESYSTEM_QUERY_CONFIG_PATH=.jaato/filesystem_query.json
# PERMISSION_CONFIG_PATH=.jaato/permissions.json
# REFERENCES_CONFIG_PATH=.jaato/references.json
# TODO_CONFIG_PATH=.jaato/todo.json
# Trace log file for subagent debug output (useful with rich terminal UIs)
# Default: /tmp/rich_client_trace.log
# Set to empty string to disable
# JAATO_TRACE_LOG=/tmp/rich_client_trace.log
